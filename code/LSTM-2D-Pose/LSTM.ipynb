{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Human Activity Recognition - 2D Pose Input\n",
    "\n",
    "This experiment aims to determine the level of accuracy attainable in activity recognition using a 2D body pose dataset and an LSTM RNN. This involves classifying the following six types of human movement:\n",
    "\n",
    "- JUMPING,\n",
    "- JUMPING_JACKS,\n",
    "- BOXING,\n",
    "- WAVING_2HANDS,\n",
    "- WAVING_1HAND,\n",
    "- CLAPPING_HANDS.\n",
    "\n",
    "The motivations behind this experiment are:\n",
    "\n",
    "-  To determine if 2D pose has comparable accuracy to 3D pose for use in activity recognition. This would allow the use of RGB only cameras for human and animal pose estimation, as opposed to RGBD or a large motion capture dataset.\n",
    "\n",
    "\n",
    "- To determine if  2D pose has comparable accuracy to using raw RGB images for use in activity recognition. This is based on the idea that limiting the input feature vector can help to deal with a limited dataset, as is likely to occur in animal activity recognition, by allowing for a smaller model to be used (citation required).\n",
    "\n",
    "\n",
    "- To verify the concept for use in future works involving behaviour prediction from motion in 2D images.\n",
    "\n",
    "\n",
    "## Dataset overview\n",
    "\n",
    "The dataset consists of pose estimations, made using the software OpenPose (https://github.com/CMU-Perceptual-Computing-Lab/openpose's) on a subset of the Berkeley Multimodal Human Action Database (MHAD) dataset http://tele-immersion.citris-uc.org/berkeley_mhad.\n",
    "\n",
    "This dataset is comprised of 12 subjects doing the 6 listed actions for 5 repetitions, filmed from 4 angles, repeated 5 times each.  \n",
    "In total, there are 1438 videos (2 were missing) made up of 211200 individual frames.\n",
    "\n",
    "The below image is an example of the 4 camera views during the 'boxing' action for subject 1\n",
    "\n",
    "![alt text](boxing_all_views .gif.png \"Title\")\n",
    "\n",
    "The input for the LSTM is the 2D position of 18 joints across a timeseries of frames numbering n_steps (window-width), with an associated class label for the frame series.  \n",
    "A single frame's input (where j refers to a joint) is stored as:\n",
    "\n",
    "[  j0_x,  j0_y, j1_x, j1_y , j2_x, j2_y, j3_x, j3_y, j4_x, j4_y, j5_x, j5_y, j6_x, j6_y, j7_x, j7_y, j8_x, j8_y, j9_x, j9_y, j10_x, j10_y, j11_x, j11_y, j12_x, j12_y, j13_x, j13_y, j14_x, j14_y, j15_x, j15_y, j16_x, j16_y, j17_x, j17_y ]\n",
    "\n",
    "For the following experiment, very little preprocessing has been done to the dataset.  \n",
    "The following steps were taken:\n",
    "1. openpose run on individual frames, for each subject, action and view, outputting JSON of 18 joint x and y position keypoints and accuracies per frame\n",
    "2. JSONs converted into txt format, keeping only x and y positions of each frame, action being performed during frame, and order of frames. This is used to create a database of associated activity class number and corresponding series of joint 2D positions\n",
    "3. No further prepossessing was performed.  \n",
    "\n",
    "In some cases, multiple people were detected in each frame, in which only the first detection was used.\n",
    "\n",
    "The data has not been normalised with regards to subject position in the frame, motion across frame (if any), size of the subject, speed of action etc. It is essentially the raw 2D position of each joint viewed from a stationary camera.  \n",
    "In many cases, individual joints were not located and a position of [0.0,0.0] was given for that joint\n",
    "\n",
    "A summary of the dataset used for input is:\n",
    "\n",
    " - 211200 individual images \n",
    " - n_steps = 33 frames (~=1.5s at 22Hz)\n",
    " - Images with noisy pose detection (detection of >=2 people) = 5132  \n",
    " - Training_split = 0.8\n",
    "   - Length X_train = 4519\n",
    "   - Length X_test = 1197\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Training and Results below: \n",
    "Training took approximately 2 mins running on a single GTX1080Ti, and was run for 2,800,000 iterations with a batch size of 1500  (600 epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
    "from sklearn import metrics\n",
    "from random import randint\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Constants\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [    \n",
    "    \"JUMPING\",\n",
    "    \"JUMPING_JACKS\",\n",
    "    \"BOXING\",\n",
    "    \"WAVING_2HANDS\",\n",
    "    \"WAVING_1HAND\",\n",
    "    \"CLAPPING_HANDS\"\n",
    "\n",
    "] \n",
    "DATASET_PATH = \"data/HAR_pose_activities/database/\"\n",
    "\n",
    "X_train_path = DATASET_PATH + \"x_train.txt\"\n",
    "X_test_path = DATASET_PATH + \"x_test.txt\"\n",
    "\n",
    "y_train_path = DATASET_PATH + \"y_train.txt\"\n",
    "y_test_path = DATASET_PATH + \"y_test.txt\"\n",
    "\n",
    "n_steps = 33 # 33 timesteps per series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load \"X\" (the neural network's training and testing inputs)\n",
    "\n",
    "def load_X(X_path):\n",
    "    file = open(X_path, 'r')\n",
    "    # Read dataset from disk, dealing with text files' syntax\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',') for row in file\n",
    "        ]], \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    file.close()\n",
    "    blocks = int(len(X_) / n_steps)\n",
    "    \n",
    "    X_ = np.array(np.split(X_,blocks))\n",
    "\n",
    "    return X_ #np.transpose(np.array(X_), (1, 2, 0))\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    # Read dataset from disk, dealing with text file's syntax\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]], \n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    \n",
    "    # for 0-based indexing \n",
    "    return y_ - 1\n",
    "\n",
    "X_train = load_X(X_train_path)\n",
    "X_test = load_X(X_test_path)\n",
    "#print X_test\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n",
    "# proof that it actually works for the skeptical: replace labelled classes with random classes to train on\n",
    "#for i in range(len(y_train)):\n",
    "#    y_train[i] = randint(0, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Parameters:\n",
    "\n",
    "Here are some core parameter definitions for the training. \n",
    "\n",
    "The whole neural network's structure could be summarised by enumerating those parameters and the fact an LSTM is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4519\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "((4519, 33, 36), (1197, 1), 250.95729, 125.17004)\n",
      "\n",
      "The dataset has not been preprocessed, is not normalised etc\n"
     ]
    }
   ],
   "source": [
    "# Input Data \n",
    "\n",
    "training_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)  # num testing series\n",
    "#n_steps = len(X_train[0])  # num timesteps per series\n",
    "n_input = len(X_train[0][0])  # num input parameters per timestep\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "print training_data_count\n",
    "training_iters = training_data_count *300  # Loop 600 times on the dataset\n",
    "batch_size = 1500\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "# Some debugging info\n",
    "\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_train.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"\\nThe dataset has not been preprocessed, is not normalised etc\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_RNN(_X, _weights, _biases):\n",
    "    # Function returns a tensorflow LSTM (RNN) artificial neural network from given parameters. \n",
    "    # Moreover, two LSTM cells are stacked which adds deepness to the neural network. \n",
    "    # Note, some code of this notebook is inspired from an slightly different \n",
    "    # RNN architecture used on another dataset, some of the credits goes to \n",
    "    # \"aymericdamien\" under the MIT license.\n",
    "\n",
    "    # (NOTE: This step could be greatly optimised by shaping the dataset once\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    #print(_X.shape)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, n_input]) \n",
    "    # new shape: (n_steps*batch_size, n_input)\n",
    "    \n",
    "    # Linear activation\n",
    "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(_X, n_steps, 0) \n",
    "    # new shape: n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    # Get LSTM cell output\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "\n",
    "    # Get last time step's output feature for a \"many to one\" style classifier, \n",
    "    # as in the image describing RNNs at the top of this page\n",
    "    lstm_last_output = outputs[-1]\n",
    "    \n",
    "    # Linear activation\n",
    "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n",
    "\n",
    "\n",
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index] \n",
    "\n",
    "    return batch_s\n",
    "\n",
    "\n",
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes \n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = int(np.max(y_)) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Graph input/output\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Graph weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "pred = LSTM_RNN(x, weights, biases)\n",
    "\n",
    "# Loss, optimizer and evaluation\n",
    "l2 = lambda_loss_amount * sum(\n",
    "    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n",
    ") # L2 loss prevents this overkill neural network to overfit the data\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #1500:   Batch Loss = 4.112636, Accuracy = 0.00266666663811\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.58607816696, Accuracy = 0.131161242723\n",
      "Training iter #30000:   Batch Loss = 2.603852, Accuracy = 0.474666655064\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.86577820778, Accuracy = 0.355054289103\n",
      "Training iter #60000:   Batch Loss = 3.030646, Accuracy = 0.0640000030398\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.75168466568, Accuracy = 0.389306604862\n",
      "Training iter #90000:   Batch Loss = 2.574919, Accuracy = 0.398666679859\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.61160087585, Accuracy = 0.399331659079\n",
      "Training iter #120000:   Batch Loss = 2.296716, Accuracy = 0.652000010014\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.46360015869, Accuracy = 0.472013354301\n",
      "Training iter #150000:   Batch Loss = 2.671354, Accuracy = 0.191333338618\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.42735385895, Accuracy = 0.4711779356\n",
      "Training iter #180000:   Batch Loss = 2.007279, Accuracy = 0.727999985218\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.71445560455, Accuracy = 0.379281550646\n",
      "Training iter #210000:   Batch Loss = 2.886149, Accuracy = 0.253333330154\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.71667790413, Accuracy = 0.389306604862\n",
      "Training iter #240000:   Batch Loss = 2.810987, Accuracy = 0.293999999762\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.61134910583, Accuracy = 0.42355889082\n",
      "Training iter #270000:   Batch Loss = 2.379930, Accuracy = 0.537999987602\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.55813169479, Accuracy = 0.422723472118\n",
      "Training iter #300000:   Batch Loss = 2.657007, Accuracy = 0.129999995232\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.36130285263, Accuracy = 0.498746871948\n",
      "Training iter #330000:   Batch Loss = 2.237890, Accuracy = 0.546666681767\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.31831812859, Accuracy = 0.465330004692\n",
      "Training iter #360000:   Batch Loss = 2.109836, Accuracy = 0.78733330965\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.22998285294, Accuracy = 0.519632399082\n",
      "Training iter #390000:   Batch Loss = 2.524610, Accuracy = 0.169333338737\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.19295215607, Accuracy = 0.50710105896\n",
      "Training iter #420000:   Batch Loss = 1.801905, Accuracy = 0.827333331108\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.16120815277, Accuracy = 0.53634083271\n",
      "Training iter #450000:   Batch Loss = 2.140948, Accuracy = 0.668666660786\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.12802433968, Accuracy = 0.548036754131\n",
      "Training iter #480000:   Batch Loss = 2.871696, Accuracy = 0.0740000009537\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.36504268646, Accuracy = 0.426065176725\n",
      "Training iter #510000:   Batch Loss = 1.802205, Accuracy = 0.700666666031\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.32323026657, Accuracy = 0.469507098198\n",
      "Training iter #540000:   Batch Loss = 2.224713, Accuracy = 0.43599998951\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.30688405037, Accuracy = 0.501253128052\n",
      "Training iter #570000:   Batch Loss = 2.795383, Accuracy = 0.322666674852\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.3547501564, Accuracy = 0.418546378613\n",
      "Training iter #600000:   Batch Loss = 1.834262, Accuracy = 0.835333347321\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.27189707756, Accuracy = 0.492898911238\n",
      "Training iter #630000:   Batch Loss = 2.478426, Accuracy = 0.211333334446\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.29376530647, Accuracy = 0.488721817732\n",
      "Training iter #660000:   Batch Loss = 2.441900, Accuracy = 0.415333330631\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.24242401123, Accuracy = 0.509607374668\n",
      "Training iter #690000:   Batch Loss = 1.960281, Accuracy = 0.782666683197\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.16593146324, Accuracy = 0.533834576607\n",
      "Training iter #720000:   Batch Loss = 2.409727, Accuracy = 0.358666658401\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.16680812836, Accuracy = 0.53634083271\n",
      "Training iter #750000:   Batch Loss = 2.014868, Accuracy = 0.582000017166\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.14768052101, Accuracy = 0.532163739204\n",
      "Training iter #780000:   Batch Loss = 2.014639, Accuracy = 0.659333348274\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.14568209648, Accuracy = 0.512113630772\n",
      "Training iter #810000:   Batch Loss = 2.426723, Accuracy = 0.341333329678\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.11739087105, Accuracy = 0.543024241924\n",
      "Training iter #840000:   Batch Loss = 1.797904, Accuracy = 0.681999981403\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.10036349297, Accuracy = 0.535505414009\n",
      "Training iter #870000:   Batch Loss = 2.110841, Accuracy = 0.554666638374\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.10885453224, Accuracy = 0.518796980381\n",
      "Training iter #900000:   Batch Loss = 2.495872, Accuracy = 0.32800000906\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.07768535614, Accuracy = 0.523809552193\n",
      "Training iter #930000:   Batch Loss = 1.792802, Accuracy = 0.750666677952\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.04536390305, Accuracy = 0.559732675552\n",
      "Training iter #960000:   Batch Loss = 2.011504, Accuracy = 0.510666668415\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.96160197258, Accuracy = 0.582289040089\n",
      "Training iter #990000:   Batch Loss = 2.034618, Accuracy = 0.52133333683\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.90737342834, Accuracy = 0.60150372982\n",
      "Training iter #1020000:   Batch Loss = 1.724092, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.8686645031, Accuracy = 0.624060153961\n",
      "Training iter #1050000:   Batch Loss = 1.965371, Accuracy = 0.483333319426\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.8790872097, Accuracy = 0.604010045528\n",
      "Training iter #1080000:   Batch Loss = 1.795018, Accuracy = 0.657999992371\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.8541367054, Accuracy = 0.61236423254\n",
      "Training iter #1110000:   Batch Loss = 1.771090, Accuracy = 0.689999997616\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.82324957848, Accuracy = 0.619047641754\n",
      "Training iter #1140000:   Batch Loss = 2.168770, Accuracy = 0.350666671991\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.9348886013, Accuracy = 0.602339208126\n",
      "Training iter #1170000:   Batch Loss = 1.630201, Accuracy = 0.77133333683\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.90850698948, Accuracy = 0.598997473717\n",
      "Training iter #1200000:   Batch Loss = 1.881557, Accuracy = 0.676666676998\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.86122989655, Accuracy = 0.610693395138\n",
      "Training iter #1230000:   Batch Loss = 2.313853, Accuracy = 0.340000003576\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.81528449059, Accuracy = 0.635756075382\n",
      "Training iter #1260000:   Batch Loss = 1.652948, Accuracy = 0.67733335495\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.82122838497, Accuracy = 0.624895572662\n",
      "Training iter #1290000:   Batch Loss = 1.757161, Accuracy = 0.653333306313\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.79825484753, Accuracy = 0.624060153961\n",
      "Training iter #1320000:   Batch Loss = 1.944034, Accuracy = 0.51599997282\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.73201811314, Accuracy = 0.649958252907\n",
      "Training iter #1350000:   Batch Loss = 1.528463, Accuracy = 0.81400001049\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.74183320999, Accuracy = 0.633249819279\n",
      "Optimization Finished!\n",
      "FINAL RESULT: Batch Loss = 1.7745320797, Accuracy = 0.624917030334\n"
     ]
    }
   ],
   "source": [
    "# To keep track of training's performance\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "# Launch the graph\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Perform Training steps with \"batch_size\" amount of example data at each loop\n",
    "step = 1\n",
    "while step * batch_size <= training_iters:\n",
    "    batch_xs =         extract_batch_size(X_train, step, batch_size)\n",
    "    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size))\n",
    "    if len(batch_ys[0]) < n_classes:\n",
    "        temp_ys = np.zeros((batch_size, n_classes))\n",
    "        temp_ys[:batch_ys.shape[0],:batch_ys.shape[1]] = batch_ys\n",
    "        batch_ys = temp_ys\n",
    "        #print temp_ys\n",
    "        \n",
    "    \n",
    "\n",
    "    # Fit training using batch data\n",
    "    _, loss, acc = sess.run(\n",
    "        [optimizer, cost, accuracy],\n",
    "        feed_dict={\n",
    "            x: batch_xs, \n",
    "            y: batch_ys\n",
    "        }\n",
    "    )\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)\n",
    "    \n",
    "    # Evaluate network only at some steps for faster training: \n",
    "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
    "        \n",
    "        # To not spam console, show training accuracy/loss in this \"if\"\n",
    "        print(\"Training iter #\" + str(step*batch_size) + \\\n",
    "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "        \n",
    "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
    "        loss, acc = sess.run(\n",
    "            [cost, accuracy], \n",
    "            feed_dict={\n",
    "                x: X_test,\n",
    "                y: one_hot(y_test)\n",
    "            }\n",
    "        )\n",
    "        test_losses.append(loss)\n",
    "        test_accuracies.append(acc)\n",
    "        print(\"PERFORMANCE ON TEST SET: \" + \\\n",
    "              \"Batch Loss = {}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Accuracy for test data\n",
    "\n",
    "one_hot_predictions, accuracy, final_loss = sess.run(\n",
    "    [pred, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_train,\n",
    "        y: one_hot(y_train)\n",
    "    }\n",
    ")\n",
    "\n",
    "test_losses.append(final_loss)\n",
    "test_accuracies.append(accuracy)\n",
    "\n",
    "print(\"FINAL RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss) + \\\n",
    "      \", Accuracy = {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW RESULT: Batch Loss = 1.7745320797, Accuracy = 0.624917030334\n"
     ]
    }
   ],
   "source": [
    "one_hot_predictions1, accuracy1, final_loss1 = sess.run(\n",
    "    [pred, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_test,\n",
    "        y: one_hot(y_test)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"NEW RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss1) + \\\n",
    "      \", Accuracy = {}\".format(accuracy1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "#plt.plot(indep_train_axis, np.array(train_losses),     \"b--\", label=\"Train losses\")\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(\n",
    "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
    "    [training_iters]\n",
    ")\n",
    "#plt.plot(indep_test_axis, np.array(test_losses), \"b-\", linewidth=2.0, label=\"Test losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"b-\", linewidth=2.0, label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='lower right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training iteration')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Results\n",
    "\n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"Created using test set of {} datapoints, normalised to % of each class in the test dataset\".format(len(y_test)))\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "\n",
    "\n",
    "#print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "\n",
    "# Plot Results: \n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix, \n",
    "    interpolation='nearest', \n",
    "    cmap=plt.cm.Blues\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Overall Accuracy of 92.65% is fantastic, considering that training took <2mins.\n",
    "There are significant spikes in decreased accuracy even far into training, which suggests the need for more data.\n",
    "\n",
    "Noticeable confusion between activities of Clapping hands and boxing, which is understandable.\n",
    "\n",
    "\n",
    "In terms of the applicability of this to a wider dataset, I would imagine that it would be able to work for any activities in which the training included a views from all angles to be tested on. It would be interesting to see it's applicability to other, in-between views.\n",
    "\n",
    "This experiment confirms the idea that 2D pose can be used for activity recognition, and provides verification to continue onto use of 2D pose for behaviour estimation.\n",
    "\n",
    "\n",
    "## Future Works\n",
    "\n",
    "Possibility to extend into a bidirectional-LSTM   (https://github.com/guillaume-chevalier/HAR-stacked-residual-bidir-LSTMs)\n",
    "\n",
    "Use on subtler activity classes and perhaps `normal vs abnormal` activity\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "The dataset can be found at http://tele-immersion.citris-uc.org/berkeley_mhad released under the BSD-2 license\n",
    ">Copyright (c) 2013, Regents of the University of California All rights reserved.\n",
    "\n",
    "The network used in this experiment is based on the following, available under the [MIT License](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition/blob/master/LICENSE). :\n",
    "> Guillaume Chevalier, LSTMs for Human Activity Recognition, 2016\n",
    "> https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert this notebook to a README for the GitHub project's title page:\n",
    "!jupyter nbconvert --to markdown LSTM.ipynb\n",
    "!mv LSTM.md README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
